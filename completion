import argparse
import torch
import torch.backends.cudnn as cudnn
import math

import numpy as np
import mcubes
import trimesh

from timm.models import create_model
from engine_for_diffusion import VirScan

from scan_dataset import ShapeNet, category_ids
import utils
from engine_for_diffusion import process_idx, sort


def get_args():
    parser = argparse.ArgumentParser('script', add_help=False)
    parser.add_argument('--model_pth', default='/checkpoint-.pth', type=str, help='checkpoint path of model')

    parser.add_argument('--device', default='cuda',
                        help='device to use for training / testing')
    # Model parameters
    parser.add_argument('--model', default='discrete_diffusion', type=str, metavar='MODEL')

    parser.add_argument('--vqvae', default='vqvae_512', type=str, metavar='MODEL')

    parser.add_argument('--vqvae_pth', default='..../checkpoint-.pth', type=str, metavar='MODEL')

    parser.add_argument('--sample_n', default=1, type=int, help='Number of generate results')

    parser.add_argument('--data_path', default=None, type=str, help='Data path')

    return parser.parse_args()


def get_model(args):
    model = create_model(
        args.model,
    )

    return model


def sample_step(model, args, condition, Xct_pos):

    model.num_timesteps = 100

    sample = model.sample_mask(condition, Xct_pos, args.sample_n)

    index, g, m, l = sample.chunk(4, 1)
    g = g.sub(1024)
    m = m.sub(1024+256)
    l = l.sub(1024+256+256)

    return index, g, m, l


def delete_null(Xct, encodings, vis):

    vis = vis[:, :torch.argmax(vis)-1]
    Xct = torch.gather(Xct, 1, vis.unsqueeze(-1).repeat(1, 1, 3))
    encodings = torch.gather(encodings, 1, vis)

    return Xct, encodings, vis

def main(args):
    print(args)

    device = torch.device(args.device)
    cudnn.benchmark = True

    model = get_model(args)
    model.to(device)
    checkpoint = torch.load(args.model_pth, map_location='cpu')
    model.load_state_dict(checkpoint['model'])
    model.eval()

    vqvae = create_model(args.vqvae)
    vqvae.to(device)
    checkpoint = torch.load(args.vqvae_pth, map_location='cpu')
    vqvae.load_state_dict(checkpoint['model'])
    vqvae.eval()

    density = 128
    gap = 2. / density
    x = np.linspace(-1, 1, density + 1)
    y = np.linspace(-1, 1, density + 1)
    z = np.linspace(-1, 1, density + 1)
    xv, yv, zv = np.meshgrid(x, y, z)
    grid = torch.from_numpy(np.stack([xv, yv, zv]).astype(np.float32)).view(3, -1).transpose(0, 1)[None].to(device, non_blocking=True)  ### 这里还是在建立grid

    N = 5000

    with torch.no_grad():

        torch.manual_seed(36)

        metric_loggers = []
        for category, category_id in category_ids.items():
            metric_logger = utils.MetricLogger(delimiter="  ")
            metric_loggers.append(metric_logger)
            header = 'Test:'

            dataset_test = ShapeNet(args.data_path, split='test', categories=['04530566'], transform=None,
                                    sampling=False, return_surface=True, surface_sampling=2048, context_N=1024)
            sampler_test = torch.utils.data.SequentialSampler(dataset_test)
            data_loader_test = torch.utils.data.DataLoader(
                dataset_test, sampler=sampler_test,
                batch_size=1,
                num_workers=12,
                drop_last=False,
            )
            step = 0
            for batch in metric_logger.log_every(data_loader_test, 10, header):
                _, Xbd, Xct = batch
                step += 1

                surface = Xct

                surface = surface.to(device, non_blocking=True)


                _, _, Xct_centers_quantized, _, _, Xct_encodings, Xct_centers = vqvae.encode(surface)

                Xct_centers_quantized, Xct_encodings, Xct_centers = sort(Xct_centers_quantized, Xct_encodings, Xct_centers)

                Xct_centers_quantized, Xct_encodings, vis = VirScan(Xct_centers, Xct_centers_quantized, Xct_encodings)

                Xct_centers_quantized, Xct_encodings, vis = delete_null(Xct_centers_quantized, Xct_encodings, vis)

                condition, Xct_centers = process_idx(Xct_encodings, Xct_centers_quantized)

                latent, x, y, z = sample_step(model, args, condition, Xct_centers)

                centers = torch.cat([x[:, :, None], y[:, :, None], z[:, :, None]], dim=2).float() / 255.0 * 2 - 1



                latent = vqvae.codebook.embedding(latent)

                if args.sample_n != 1:

                    for j in range(args.sample_n):
                        logits = torch.cat([vqvae.decoder(latent[j,...][None], centers[j,...][None], grid[:, i * N:(i + 1) * N])[0] for i in range(math.ceil(grid.shape[1] / N))], dim=1)  ### 这里好像是对grid分块送入然后在进行拼接处理  ### math.ceil向上输出整数

                        volume = logits.view(density + 1, density + 1, density + 1).permute(1, 0, 2).cpu().numpy()
                        verts, faces = mcubes.marching_cubes(volume, 0)

                        verts *= gap
                        verts -= 1

                        m = trimesh.Trimesh(verts, faces)
                        m.export('..../sample_{}_{}.obj'.format(step, j+1))

                elif args.sample_n == 1:
                    logits = torch.cat([vqvae.decoder(latent, centers, grid[:, i * N:(i + 1) * N])[0] for i in range(math.ceil(grid.shape[1] / N))], dim=1)  ### 这里好像是对grid分块送入然后在进行拼接处理  ### math.ceil向上输出整数

                    volume = logits.view(density + 1, density + 1, density + 1).permute(1, 0, 2).cpu().numpy()
                    verts, faces = mcubes.marching_cubes(volume, 0)

                    verts *= gap
                    verts -= 1

                    m = trimesh.Trimesh(verts, faces)
                    m.export('..../sample_{}.obj'.format(step))


if __name__ == '__main__':
    opts = get_args()
    main(opts)
